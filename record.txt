<img src="mean_std.png" alt="mean_std" width="400" height="300"/>
> Note: The output layer's neuron count often differs from the input layer. Each layer can have a distinct number of neurons, indicating its 'size' or capacity.
>
## Reference:
- [Watch the video on YouTube](https://youtube.com/watch?v=jTzJ9zjC8nU)
$\text{SSR}(a, b) = \sum\limits_{i=1}^{n} (y_i - ax_i - b)^2$
matrix:
$$
\begin{pmatrix}

0.8944272 & 0.4472136\\
-0.4472136 & -0.8944272
\end{pmatrix}
\begin{pmatrix}
10 & 0\\ 
0 & 5
\end{pmatrix}
$$

Editor: https://stackedit.io/app#

1.ffnn.md✅已发csdn+知乎
2.linear-regression.md✅
3.variance&standarDeviation.md✅
4.Covariance.md ❌ need further improvement for pca
5.Linearity.md❌ need further improvement for why the product of the standard deviations of x and y is normalization? Which is correlated to correlation.
6.p_values.md✅
7.Correlation.md✅
8.r-squared.md✅
9.statistical-significance.md✅
10.Standard-Deviation-vs-Standard-Error.md✅
11.Confidence-Intervals.md✅
12.least-squared.md✅
13.calculus.md✅
14.gradient-descent.md✅ need further math formula format improvement, need format and refrase
15.Neural-Network.md✅
16.backpropagation.md✅ need format and rephrase
17.relu.md✅ need format and rephrase
18.activation-functions.md✅ 已发csdn+知乎 need format and rephrase, Comparison with different activation Functions, why and when choose which
19.sigmoid.md✅已发csdn+知乎
20.tanh.md✅
21.neural-network-models.md✅
22.Linear-Layer.md✅ need further modification
23.softmax.md✅已发csdn,未发知乎
24.Cross_Entropy_Loss.md✅已发csdn,未发知乎 why dldlogits not dldsoftmax???
25.MSE_Loss.md✅已发csdn,未发知乎
26.Loss_Functions.md✅已发csdn,未发知乎
27.sgd.md✅已发csdn,未发知乎
28.one-hot-encoding.md✅



Chain rule
Cumulative Distribution Function (CDF)
Standard Gaussian Distributio
gelu
logistic regression
t-sne
implicit function
scalar function
Directional Derivative:

why gradient" refers to a vector that points in the direction of the greatest rate of increase  give specific example???
why the product of the standard deviations of x and y is normalization?
