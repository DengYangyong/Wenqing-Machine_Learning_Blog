Entropy: Entropy is a measure of uncertainty or randomness within a single probability distribution. It is not typically used as a loss function in machine learning models but rather as a theoretical concept to quantify the amount of information or the unpredictability in a dataset.

Cross-Entropy: A measure of the difference between two distributions, widely used as a loss function in machine learning for classification tasks due to its properties of penalizing incorrect predictions and being suitable for probability distributions.
